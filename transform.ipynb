{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Entrega 2 - Transformation and Processing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from deltalake import write_deltalake, DeltaTable\n",
    "from datetime import datetime\n",
    "import os\n",
    "pd.options.display.max_rows = None # Visualizar todas las filas de los df\n",
    "pd.options.display.max_columns = None # Visualizar todas las columnas de los df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Current Weather**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos de la última hora (20) agregados correctamente a la capa silver.\n",
      "Cantidad total de registros en la silver deltatable actualizada: 27\n"
     ]
    }
   ],
   "source": [
    "# Traemos los datos desde la capa Bronze\n",
    "bronze_dir_current = 'datalake/bronze/current_weather_data'\n",
    "current_data = DeltaTable(bronze_dir_current).to_pandas()\n",
    "\n",
    "# Validar si Bronze contiene datos\n",
    "if current_data.empty:\n",
    "    print(\"No hay datos disponibles en Bronze para procesar.\")\n",
    "else:\n",
    "    # Filtrar los datos por la fecha más reciente\n",
    "    latest_date = current_data['date'].max()\n",
    "\n",
    "    # Filtrar los datos de la hora más reciente dentro de la fecha más reciente\n",
    "    latest_hour = current_data[current_data['date'] == latest_date]['hour_time'].max()\n",
    "\n",
    "    # Crear una máscara booleana para los registros que no cumplen con las condiciones\n",
    "    mask_to_drop = (current_data['date'] != latest_date) | (current_data['hour_time'] != latest_hour)\n",
    "    \n",
    "    # Eliminar los registros que no cumplen con la máscara booleana usando drop con axis=0\n",
    "    current_data = current_data.drop(current_data[mask_to_drop].index, axis=0)\n",
    "\n",
    "    # Setear en un diccionario las columnas y sus futuros tipos de datos compatibles con silver\n",
    "    conversion_mapping = {\n",
    "        'id': 'int32',\n",
    "        'visibility': 'int16',\n",
    "        'name': 'string',\n",
    "        'coord.lon': 'float32',\n",
    "        'coord.lat': 'float32',\n",
    "        'main.temp': 'int8',\n",
    "        'main.feels_like': 'int8',\n",
    "        'main.temp_min': 'int8',\n",
    "        'main.temp_max': 'int8',\n",
    "        'main.pressure': 'int16',\n",
    "        'main.humidity': 'int16',\n",
    "        'main.sea_level': 'int16',\n",
    "        'main.grnd_level': 'int16',\n",
    "        'wind.speed': 'float32',\n",
    "        'wind.deg': 'int16',\n",
    "        'date': 'datetime64[ns]',\n",
    "        'hour_time': 'int8'\n",
    "    }\n",
    "\n",
    "    # Aplicar conversiones\n",
    "    current_data = current_data.astype(conversion_mapping)\n",
    "\n",
    "    # Directorio de la capa silver\n",
    "    silver_dir_current = 'datalake/silver/current_weather_data'\n",
    "    \n",
    "    # Validar si el directorio silver existe\n",
    "    if not os.path.exists(silver_dir_current):\n",
    "        # Si no existe, inicializar silver con los datos actuales\n",
    "        write_deltalake(\n",
    "            table_or_uri=silver_dir_current,\n",
    "            data=current_data,\n",
    "            mode='append',\n",
    "            partition_by=['date', 'hour_time'],\n",
    "        )\n",
    "        print(\"Delta Lake (silver) inicializado con los datos actuales.\")\n",
    "    else:\n",
    "        try:\n",
    "            # Obtener los datos existentes que hay actualmente en Silver\n",
    "            silver_data = DeltaTable(silver_dir_current).to_pandas()\n",
    "\n",
    "            # Validar si ya existen datos para la misma combinación de 'date' y 'hour_time' sin afectar el esquema\n",
    "            date_to_check = current_data['date'].iloc[0]\n",
    "            hour_to_check = current_data['hour_time'].iloc[0]\n",
    "\n",
    "            # Filtrar para verificar si ya existe el dato en Silver\n",
    "            existing_data = silver_data[(silver_data['date'] == date_to_check) & (silver_data['hour_time'] == hour_to_check)]\n",
    "\n",
    "            if not existing_data.empty:\n",
    "                print(f\"Ya existen datos en silver para la fecha {date_to_check} y la hora {hour_to_check}. La inserción ha sido cancelada.\")\n",
    "            else:\n",
    "                # Si no hay duplicados, escribir los datos transformados en el silver Delta Lake\n",
    "                write_deltalake(\n",
    "                    table_or_uri=silver_dir_current,\n",
    "                    data=current_data,\n",
    "                    mode='append', # Usa 'append' para realizar incrementos en cada extracción\n",
    "                    partition_by=['date', 'hour_time'] # Columnas de partición\n",
    "                )\n",
    "                print(f\"Datos de la última hora ({hour_to_check}) agregados correctamente a la capa silver.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al cargar los datos en la capa silver: {e}\")\n",
    "\n",
    "# Ver cantidad total de registros actuales de la silver deltatable\n",
    "if os.path.exists(silver_dir_current):\n",
    "    current_dt = DeltaTable(silver_dir_current)\n",
    "    print(f\"Cantidad total de registros en la silver deltatable actualizada: {current_dt.to_pandas().shape[0]}\")\n",
    "\n",
    "# Descomentar las siguientes lineas para imprimir el último dataframe transformado\n",
    "# current_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. History Weather**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad total de registros en la silver deltatable actualizada: 40\n"
     ]
    }
   ],
   "source": [
    "# Traemos los datos desde 'datalake/history_weather_data/bronze'\n",
    "history_data = DeltaTable('datalake/bronze/history_weather_data').to_pandas()\n",
    "\n",
    "# Diccionario de las columnas innecesarias\n",
    "columns_to_drop = ['rain.3h', 'sys.pod', 'wind.gust', 'clouds.all', \n",
    "                   'main.temp_kf', 'dt', 'pop', 'weather']\n",
    "\n",
    "# Eliminar las columnas innecesarias del DataFrame\n",
    "history_data = history_data.drop(columns=columns_to_drop)\n",
    "\n",
    "# Mapeo: asignar tipos de datos correspondiente y reducir el consumo de memoria\n",
    "conversion_mapping = {\n",
    "    \"dt_txt\": \"datetime64[ns]\",\n",
    "    \"visibility\": \"int16\",\n",
    "    \"main.temp\": \"int8\", \n",
    "    \"main.feels_like\": \"int8\", \n",
    "    \"main.temp_min\": \"int8\",\n",
    "    \"main.temp_max\": \"int8\",\n",
    "    \"main.pressure\": \"int16\",\n",
    "    \"main.sea_level\": \"int16\",\n",
    "    \"main.grnd_level\": \"int16\",\n",
    "    \"main.humidity\": \"int8\",\n",
    "    \"wind.speed\": \"int8\",\n",
    "    \"wind.deg\": \"int16\"\n",
    "}\n",
    "\n",
    "# Realizar el casteo utilizando el mapeo previo\n",
    "history_data = history_data.astype(conversion_mapping)\n",
    "\n",
    "# Crear nuevas columnas 'date' y 'time' a partir de 'dt_txt'\n",
    "history_data['date'] = history_data['dt_txt'].dt.date\n",
    "history_data['hour_time'] = history_data['dt_txt'].dt.hour\n",
    "\n",
    "# Eliminar la columna 'dt_txt'\n",
    "history_data.drop(columns=['dt_txt'], inplace=True)\n",
    "\n",
    "# Reordenar las columnas\n",
    "history_data = history_data[['date', 'hour_time', 'visibility', 'main.temp', 'main.feels_like', 'main.temp_min', \n",
    "                             'main.temp_max', 'main.pressure', 'main.sea_level', 'main.grnd_level', 'main.humidity', \n",
    "                             'wind.speed', 'wind.deg']]\n",
    "\n",
    "# URL directorio\n",
    "silver_dir_history = 'datalake/silver/history_weather_data'\n",
    "\n",
    "# Generar deltalake\n",
    "write_deltalake(\n",
    "    table_or_uri=silver_dir_history,\n",
    "    data=history_data,\n",
    "    mode='overwrite',\n",
    ")\n",
    "\n",
    "# Ver cantidad de registros en la tabla actualizada\n",
    "history_dt = DeltaTable(silver_dir_history)\n",
    "print(f'Cantidad total de registros en la silver deltatable actualizada: {history_dt.to_pandas().shape[0]}') # La cantidad se mantiene constante en 40 registros porque la data se sobreescribe\n",
    "\n",
    "# Descomentar la siguiente línea para ver el último DataFrame transformado\n",
    "# history_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
